<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Assignment Description</title>
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
            font-family: Arial, sans-serif;
            font-size: 14px;
        }
        th, td {
            border: 2px solid black;
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        td {
            vertical-align: top;
        }
    </style>
</head>
<body>

<h2>
    Guess the Behaviour
</h2>

<table>
    <tr>
        <th>Summary</th>
        <td>
            Students are provided with a Markov Decision Process (MDP) with unknown details. Their task is to approximate the structure of the MDP and solve it using any method of their choice to obtain one of the optimal policies.
            They are also required to generate a policy directly using Q-Learning, bypassing the need to explicitly construct the underlying MDP structure. The focus of this assignment is to provide students with a non-trivial problem and challenge them to solve it using various methods.
        </td>
    </tr>
    <tr>
        <th>Topics</th>
        <td>MDPs, Value Iteration, Q-Learning</td>
    </tr>
    <tr>
        <th>Audience</th>
        <td>
            Suitable for undergraduate or graduate students enrolled in introductory courses on Artificial Intelligence or courses related to Reinforcement Learning.
        </td>
    </tr>
    <tr>
        <th>Difficulty</th>
        <td>
            Moderately challenging for undergraduates with a background in Python programming. Students are expected to complete the assignment within two weeks. 
        </td>
    </tr>
    <tr>
        <th>Strengths</th>
        <td>
            This assignment provides hands-on experience with the basics of MDPs, Reinforcement Learning, and Q-Learning, while also allowing students the opportunity to solve the problem using their own algorithms. It is structured to promote creativity and exploration.
            The assignment is implemented entirely in Python, and there is a version that integrates with the Gymnasium framework.
        </td>
    </tr>
    <tr>
        <th>Weaknesses</th>
        <td>
            The main drawback is that the assignment cannot be easily auto-graded. Additionally, it assumes a solid foundation in Python and related libraries.
        </td>
    </tr>
    <tr>
        <th>Dependencies</th>
        <td>
            A strong background in Python programming is recommended. The assignment is compatible with Python 3+ and can be run on most single-board computers, ensuring broad accessibility.
            The Gymnasium version is fully compatible with Python 3.9+.
        </td>
    </tr>
    <tr>
        <th>Variants</th>
        <td>
            This assignment is adaptable. The general version covers all the aspects of the problem, but there are several modifications that can focus on specific tasks. For example:
            <ul>
                <li>Compare performance based on initial values in the Q-Table (Exploration vs. Exploitation).</li>
                <li>Compare policy gradient methods with Q-Learning.</li>
                <li>Other possible variations.</li>
            </ul>
        </td>
    </tr>
</table>

<a href="./">
    <p>Assignment handout template</p>    
</a>

<a href="">
    <p>Source code for the environment</p>    
</a>

<a href="">
    <p>File to be edited by students</p>    
</a>

</body>
</html>
